"""Generate remediation suggestions from PRGA parity artefacts."""

from __future__ import annotations

import argparse
import json
import logging
import re
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Sequence, Tuple

logger = logging.getLogger(__name__)

__all__ = [
    "ParityReport",
    "MappingSummary",
    "PipelineSummary",
    "ParitySuggestionReport",
    "load_parity_report",
    "load_pipeline_candidates",
    "load_mapping_candidates",
    "generate_parity_suggestions",
    "build_suggestion_report",
    "write_suggestion_markdown",
    "main",
]

_DEFAULT_OUTPUT = Path("out/parity_suggestions.md")
_ROTATE_RANGE = range(1, 8)
_PERMUTATION_SCORE_THRESHOLD = 0.65
_CONFIDENCE_THRESHOLD = 0.6


@dataclass(frozen=True)
class ParityReport:
    """Structured view over the Markdown report generated by ``parity_test``."""

    report_path: Path
    success: bool
    matching_prefix: int
    limit: int
    variant: Optional[str]
    sample: Optional[str]
    mismatch_index: Optional[int]
    python_byte: Optional[int]
    lua_byte: Optional[int]
    python_context: Optional[bytes]
    lua_context: Optional[bytes]
    brute_force_attempts: Optional[int]
    brute_force_best_prefix: Optional[int]
    brute_force_best_length: Optional[int]
    recommendations: Tuple[str, ...]


@dataclass(frozen=True)
class MappingSummary:
    """Metadata describing a saved permutation/opcode mapping candidate."""

    path: Path
    name: str
    confidence: float
    permutation_score: float
    version_hint: Optional[str]


@dataclass(frozen=True)
class PipelineSummary:
    """Snapshot of a pipeline candidate sequence and its confidence."""

    index: int
    sequence: Tuple[str, ...]
    confidence: float
    version_hint: Optional[str]


@dataclass(frozen=True)
class ParitySuggestionReport:
    """Aggregated parity artefacts and the resulting textual suggestions."""

    parity_report: ParityReport
    suggestions: Tuple[str, ...]
    mapping_candidates: Tuple[MappingSummary, ...]
    pipeline_candidates: Tuple[PipelineSummary, ...]


_KV_PATTERN = re.compile(r"^\* \*\*(.+?):\*\*\s*(.+?)\s*$")
_NUMBER_PAIR_PATTERN = re.compile(r"(\d+)\s*/\s*(\d+)")
_HEX_BYTE_PATTERN = re.compile(r"0x([0-9a-fA-F]{2})")
_BACKTICK_PATTERN = re.compile(r"`([^`]+)`")
_LENGTH_PATTERN = re.compile(r"length\s+(\d+)")


def _normalise_hex_payload(value: str) -> Optional[bytes]:
    """Convert a backtick-wrapped hex string into bytes if possible."""

    match = _BACKTICK_PATTERN.search(value)
    if not match:
        text = value.strip().replace(" ", "")
    else:
        text = match.group(1).replace(" ", "")
    if not text:
        return None
    if len(text) % 2 != 0:
        text = text[:-1]
    try:
        return bytes.fromhex(text)
    except ValueError:
        return None


def _parse_int(value: str) -> Optional[int]:
    value = value.strip()
    if not value:
        return None
    try:
        if value.lower().startswith("0x"):
            return int(value, 16)
        return int(value)
    except ValueError:
        return None


def load_parity_report(path: Path) -> ParityReport:
    """Parse ``parity_test`` Markdown report into a :class:`ParityReport`."""

    if not path.exists():
        raise FileNotFoundError(path)

    text = path.read_text(encoding="utf-8")
    success = False
    matching_prefix = 0
    limit = 0
    variant: Optional[str] = None
    sample: Optional[str] = None
    mismatch_index: Optional[int] = None
    python_byte: Optional[int] = None
    lua_byte: Optional[int] = None
    python_context: Optional[bytes] = None
    lua_context: Optional[bytes] = None
    brute_force_attempts: Optional[int] = None
    brute_force_best_prefix: Optional[int] = None
    brute_force_best_length: Optional[int] = None
    recommendations: List[str] = []

    for line in text.splitlines():
        stripped = line.strip()
        if not stripped:
            continue

        kv_match = _KV_PATTERN.match(stripped)
        if kv_match:
            key = kv_match.group(1).lower()
            value = kv_match.group(2).strip()
            if key == "result":
                success = "SUCCESS" in value.upper()
            elif key == "matching prefix":
                pair = _NUMBER_PAIR_PATTERN.search(value)
                if pair:
                    matching_prefix = int(pair.group(1))
                    limit = int(pair.group(2))
            elif key == "comparison limit":
                parsed = _parse_int(value.split()[0])
                if parsed is not None:
                    limit = parsed
            elif key == "variant":
                variant = value.strip("`")
            elif key == "sample":
                sample = value.strip("`")
            elif key == "mismatch index":
                mismatch_index = _parse_int(value)
            elif key == "python byte":
                match = _HEX_BYTE_PATTERN.search(value)
                python_byte = int(match.group(1), 16) if match else _parse_int(value)
            elif key == "lua byte":
                match = _HEX_BYTE_PATTERN.search(value)
                lua_byte = int(match.group(1), 16) if match else _parse_int(value)
            elif key == "python context":
                python_context = _normalise_hex_payload(value)
            elif key == "lua context":
                lua_context = _normalise_hex_payload(value)
            continue

        if stripped.startswith("Attempts executed:"):
            brute_force_attempts = _parse_int(stripped.split(":", 1)[1])
            continue
        if stripped.startswith("Best prefix observed:"):
            pair = _NUMBER_PAIR_PATTERN.search(stripped)
            if pair:
                brute_force_best_prefix = int(pair.group(1))
            continue
        if "Best candidate key" in stripped:
            length = _LENGTH_PATTERN.search(stripped)
            if length:
                brute_force_best_length = int(length.group(1))
            continue
        if stripped.startswith("* ") and not stripped.startswith("* **"):
            recommendations.append(stripped[2:].strip())

    if limit == 0:
        limit = matching_prefix or 64

    return ParityReport(
        report_path=path,
        success=success,
        matching_prefix=matching_prefix,
        limit=limit,
        variant=variant,
        sample=sample,
        mismatch_index=mismatch_index,
        python_byte=python_byte,
        lua_byte=lua_byte,
        python_context=python_context,
        lua_context=lua_context,
        brute_force_attempts=brute_force_attempts,
        brute_force_best_prefix=brute_force_best_prefix,
        brute_force_best_length=brute_force_best_length,
        recommendations=tuple(recommendations),
    )


def load_pipeline_candidates(path: Optional[Path]) -> Tuple[PipelineSummary, ...]:
    if path is None or not path.exists():
        return ()
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, UnicodeDecodeError) as exc:
        logger.warning("Failed to parse pipeline candidates from %s: %s", path, exc)
        return ()

    pipelines = []
    for index, entry in enumerate(data.get("pipelines", []) or []):
        sequence = tuple(str(step) for step in entry.get("sequence", []) if step)
        confidence = float(entry.get("confidence", 0.0))
        version_hint = entry.get("version_hint")
        pipelines.append(PipelineSummary(index=index, sequence=sequence, confidence=confidence, version_hint=version_hint))
    pipelines.sort(key=lambda item: (-item.confidence, item.index))
    return tuple(pipelines)


def load_mapping_candidates(directory: Optional[Path]) -> Tuple[MappingSummary, ...]:
    if directory is None or not directory.exists():
        return ()

    candidates: List[MappingSummary] = []
    for path in sorted(directory.glob("*.json")):
        try:
            payload = json.loads(path.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, UnicodeDecodeError) as exc:
            logger.debug("Skipping mapping file %s: %s", path, exc)
            continue
        confidence = float(payload.get("confidence", 0.0))
        permutation_score = float(payload.get("permutation_score", 0.0))
        name = str(payload.get("name", path.stem))
        version_hint = payload.get("version_hint")
        candidates.append(
            MappingSummary(
                path=path,
                name=name,
                confidence=confidence,
                permutation_score=permutation_score,
                version_hint=version_hint,
            )
        )
    candidates.sort(key=lambda entry: (-entry.permutation_score, -entry.confidence, entry.name))
    return tuple(candidates)


def _rotl(value: int, bits: int) -> int:
    bits %= 8
    return ((value << bits) | (value >> (8 - bits))) & 0xFF


def _rotr(value: int, bits: int) -> int:
    bits %= 8
    return ((value >> bits) | (value << (8 - bits))) & 0xFF


def _derive_rotate_hint(python_byte: Optional[int], lua_byte: Optional[int]) -> Optional[Tuple[int, str]]:
    if python_byte is None or lua_byte is None:
        return None
    for bits in _ROTATE_RANGE:
        if _rotl(lua_byte, bits) == python_byte:
            return bits, "left"
        if _rotr(lua_byte, bits) == python_byte:
            return bits, "right"
    return None


def _derive_xor_hint(python_byte: Optional[int], lua_byte: Optional[int]) -> Optional[int]:
    if python_byte is None or lua_byte is None:
        return None
    delta = python_byte ^ lua_byte
    return delta if delta else None


def generate_parity_suggestions(
    report: ParityReport,
    *,
    pipeline_candidates: Sequence[PipelineSummary] = (),
    mapping_candidates: Sequence[MappingSummary] = (),
) -> List[str]:
    """Create human-readable guidance based on collected artefacts."""

    suggestions: List[str] = []
    if report.success:
        suggestions.append(
            "Parity succeeded; retain current PRGA parameters but record the configuration for regression tests."
        )
    else:
        prefix = report.matching_prefix
        base_message = "PRGA mismatch detected"
        if report.mismatch_index is not None:
            base_message += f" at byte {report.mismatch_index}"
        rotate_hint = _derive_rotate_hint(report.python_byte, report.lua_byte)
        if rotate_hint is not None:
            amount, direction = rotate_hint
            suggestions.append(
                f"{base_message} — try rotate amount {amount} ({direction})."
            )
        else:
            xor_hint = _derive_xor_hint(report.python_byte, report.lua_byte)
            if xor_hint is not None:
                suggestions.append(
                    f"{base_message}; XOR delta 0x{xor_hint:02x} suggests adjusting XOR mixing constants."
                )
            else:
                suggestions.append(f"{base_message}; review PRGA permutation and XOR parameters.")
        if report.brute_force_best_length and report.brute_force_best_prefix:
            if report.brute_force_best_prefix > prefix:
                suggestions.append(
                    "Brute-force hinted that {length}-byte keys matched {best}/{limit} bytes; ".format(
                        length=report.brute_force_best_length,
                        best=report.brute_force_best_prefix,
                        limit=report.limit,
                    )
                    + "consider testing those key lengths explicitly."
                )
        elif report.brute_force_attempts is not None and report.brute_force_attempts == 0:
            suggestions.append("Brute-force search skipped; enable --brute-force-small-keys for additional hints.")

    for summary in pipeline_candidates:
        if not summary.sequence:
            continue
        if any("perm" in step for step in summary.sequence):
            flow = " → ".join(summary.sequence)
            suggestions.append(
                "Pipeline candidate #{idx} ({flow}) scored {conf:.2f}; align rotate/permute tables for {version}.".format(
                    idx=summary.index + 1,
                    flow=flow,
                    conf=summary.confidence,
                    version=summary.version_hint or "observed variant",
                )
            )
            break

    highlighted = 0
    for candidate in mapping_candidates:
        if (
            candidate.permutation_score >= _PERMUTATION_SCORE_THRESHOLD
            or candidate.confidence >= _CONFIDENCE_THRESHOLD
        ):
            suggestions.append(
                "Permutation invert candidate {name} ({file}) likely (confidence {conf:.2f}, perm_score {perm:.2f}).".format(
                    name=candidate.name,
                    file=candidate.path.name,
                    conf=candidate.confidence,
                    perm=candidate.permutation_score,
                )
            )
            highlighted += 1
        if highlighted >= 2:
            break

    if not suggestions:
        suggestions.append("No actionable suggestions derived from parity artefacts.")

    return suggestions


def build_suggestion_report(
    report_path: Path,
    *,
    pipeline_path: Optional[Path] = None,
    mapping_dir: Optional[Path] = None,
) -> ParitySuggestionReport:
    parity_report = load_parity_report(report_path)
    pipeline_candidates = load_pipeline_candidates(pipeline_path)
    mapping_candidates = load_mapping_candidates(mapping_dir)
    suggestions = generate_parity_suggestions(
        parity_report,
        pipeline_candidates=pipeline_candidates,
        mapping_candidates=mapping_candidates,
    )
    return ParitySuggestionReport(
        parity_report=parity_report,
        suggestions=tuple(suggestions),
        mapping_candidates=tuple(mapping_candidates),
        pipeline_candidates=tuple(pipeline_candidates),
    )


def write_suggestion_markdown(report: ParitySuggestionReport, output_path: Path) -> Path:
    """Serialise the suggestion report to ``output_path`` in Markdown format."""

    output_path.parent.mkdir(parents=True, exist_ok=True)

    parity = report.parity_report
    lines = [
        "# PRGA Parity Suggestions",
        "",
        f"* **Parity report:** `{parity.report_path}`",
        f"* **Variant:** `{parity.variant or 'unknown'}`",
        f"* **Matching prefix:** {parity.matching_prefix}/{parity.limit} bytes",
        f"* **Parity result:** {'SUCCESS' if parity.success else 'FAILURE'}",
        "",
        "## Suggestions",
    ]

    if report.suggestions:
        for suggestion in report.suggestions:
            lines.append(f"* {suggestion}")
    else:
        lines.append("* No actionable suggestions derived from parity artefacts.")

    if report.pipeline_candidates:
        lines.extend(["", "## Pipeline highlights"])
        for candidate in report.pipeline_candidates[:3]:
            sequence = " → ".join(candidate.sequence) or "(empty)"
            lines.append(
                "* Candidate #{idx} ({sequence}) — confidence {conf:.2f} (version hint: {hint})".format(
                    idx=candidate.index + 1,
                    sequence=sequence,
                    conf=candidate.confidence,
                    hint=candidate.version_hint or "n/a",
                )
            )
    if report.mapping_candidates:
        lines.extend(["", "## Mapping candidates"])
        for candidate in report.mapping_candidates[:5]:
            lines.append(
                "* {name} ({file}) — confidence {conf:.2f}, perm_score {perm:.2f}{version}".format(
                    name=candidate.name,
                    file=candidate.path.name,
                    conf=candidate.confidence,
                    perm=candidate.permutation_score,
                    version=(
                        f", version hint {candidate.version_hint}"
                        if candidate.version_hint
                        else ""
                    ),
                )
            )

    output_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
    logger.info("Parity suggestions written to %s", output_path)
    return output_path


def main(argv: Optional[Sequence[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="Generate suggestions from parity artefacts")
    parser.add_argument("--report", type=Path, default=Path("out/parity_report.md"), help="Parity report generated by parity_test")
    parser.add_argument("--pipeline", type=Path, default=None, help="Pipeline candidates JSON")
    parser.add_argument("--mapping-dir", type=Path, default=None, help="Directory containing mapping candidate JSON files")
    parser.add_argument("--output", type=Path, default=_DEFAULT_OUTPUT, help="Destination Markdown file for suggestions")
    parser.add_argument("--log-level", default="INFO", help="Logging level (default: INFO)")
    args = parser.parse_args(argv)

    logging.basicConfig(level=getattr(logging, args.log_level.upper(), logging.INFO))

    try:
        report = build_suggestion_report(
            args.report,
            pipeline_path=args.pipeline,
            mapping_dir=args.mapping_dir,
        )
    except FileNotFoundError as exc:
        logger.error("Required artefact missing: %s", exc)
        return 2

    write_suggestion_markdown(report, args.output)
    return 0


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(main())
